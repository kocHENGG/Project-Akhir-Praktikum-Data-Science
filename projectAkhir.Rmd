---
title: "Project Akhir"
author: "Anis/Usamah"
date: "2022-11-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tm)
library(wordcloud2)
library(twitteR)
library(rtweet)
library(shiny)
library(syuzhet) 
library(wordcloud)
library(vroom)
library(dplyr)
library(ggplot2)
library(RColorBrewer)
library(plyr)
library(RTextTools)
library(tidytext)
library(tidyverse)
library(tidymodels)
library(plotly)
library(here)
library(DT)
library(e1071)
library(caret)

# Key auth Twitter API
consumer.api_key <- "DuixF49xDkpmA98YPoxe3tmjS"
consumer.api_secret_key <- "4qHdnw4sORhGca9S0XtbB9hQZ1lliwtJ4A25LHpwoIduMqzYOO"
access.token <- "1595430338423291904-c73aAX0ycoeKWHxAx2fk1S09Pi8D2Q"
access.token_secret <- "8kioK4IEp3oaSC5CFZYJWb2K7hsjXFtei4LqaWGUbNOck"
  
# Start authentication with OAuth
setup_twitter_oauth(consumer.api_key, consumer.api_secret_key, access.token, access.token_secret)
```

```{r}
tweets = searchTwitter('Pajak', 
                               n = 1000,
                               lang = "id",
                               retryOnRateLimit = 10e5)
text <- do.call("rbind", lapply(tweets, as.data.frame))

write.csv(text, file = 'data_pajak.csv')
View(text)
```


```{r}
#dataCleaning
data <- read.csv('data_pajak.csv')

ulasan <- data$text
reviewC <- Corpus(VectorSource(ulasan))
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
reviewclean <- tm_map(reviewC, removeURL)
removeNL <- function(y) gsub("\n", " ", y)
reviewclean <- tm_map(reviewclean, removeNL)
replacecomma <- function(y) gsub(",", "", y)
reviewclean <- tm_map(reviewclean, replacecomma)
removeRT <- function(y) gsub("RT ", "", y)
reviewclean <- tm_map(reviewclean, removeRT)
removetitik2 <- function(y) gsub(":", "", y)
reviewclean <- tm_map(reviewclean, removetitik2)
removetitikkoma <- function(y) gsub(";", " ", y)
reviewclean <- tm_map(reviewclean, removetitikkoma)
removetitik3 <- function(y) gsub("p…", "", y)
reviewclean <- tm_map(reviewclean, removetitik3)
removeamp <- function(y) gsub("&amp;", "", y)
reviewclean <- tm_map(reviewclean, removeamp)
removeUN <- function(z) gsub("@\\w+", "", z)
reviewclean <- tm_map(reviewclean, removeUN)
removesym <- function(y) gsub("ð", "", y)
reviewclean <- tm_map(reviewclean, removesym)
remove.all <- function(xy) gsub("[^[:alpha:][:space:]]*", "", xy)
reviewclean <- tm_map(reviewclean,remove.all)
reviewclean <- tm_map(reviewclean, removePunctuation)
reviewclean <- tm_map(reviewclean, tolower)

dataframe<-data.frame(text=unlist(sapply(reviewclean, `[`)), stringsAsFactors=F)
dataframe
write.csv(dataframe,file = 'dataPreprocessing.csv')
View(dataframe)
```

```{r}
kalimat2 <- read.csv('dataPreprocessing.csv')
View(kalimat2)
#skoring
kata.positif <- scan("positive-words.txt",what="character",comment.char=";")
kata.negatif <- scan("negative-words.txt",what="character",comment.char=";")
score.sentiment = function(kalimat2, kata.positif, kata.negatif,
                           .progress='none')
{
  require(plyr)
  require(stringr)
  scores = laply(kalimat2, function(kalimat, kata.positif,
                                    kata.negatif) {
    kalimat = gsub('[[:punct:]]', '', kalimat)
    kalimat = gsub('[[:cntrl:]]', '', kalimat)
    kalimat = gsub('\\d+', '', kalimat)
    kalimat = tolower(kalimat)
    list.kata = str_split(kalimat, '\\s+')
    kata2 = unlist(list.kata)
    positif.matches = match(kata2, kata.positif)
    negatif.matches = match(kata2, kata.negatif)
    positif.matches = !is.na(positif.matches)
    negatif.matches = !is.na(negatif.matches)
    score = sum(positif.matches) - (sum(negatif.matches))
    return(score)
  }, kata.positif, kata.negatif, .progress=.progress )
  scores.df = data.frame(score=scores, text=kalimat2)
  return(scores.df)}
hasil = score.sentiment(kalimat2$text, kata.positif, kata.negatif)

#mengubah nilai score menjadi sentimen
hasil$klasifikasi<- ifelse(hasil$score<0, "Negatif",ifelse(hasil$score==0,"Netral","Positif"))
hasil$klasifikasi

#menukar urutan baris
data <- hasil[c(3,1,2)]
#View(data)
write.csv(data, file = "datalabel.csv")
View(data)
```

```{r}
require(corpus)
require(plyr)

df<-read.csv("datalabel.csv",stringsAsFactors = F)
df$klasifikasi <- factor(df$klasifikasi)
glimpse(df)

set.seed(20)
df<-df[sample(nrow(df)),]
df<-df[sample(nrow(df)),]
glimpse(df)

corpus<-Corpus(VectorSource(df$text))
corpus
inspect(corpus[1:10])

#untuk membersihkan data data yang tidak dibutuhkan 
corpus.clean<-corpus%>%
    tm_map(content_transformer(tolower))%>%
    tm_map(removePunctuation)%>%
    tm_map(removeNumbers)%>%
    tm_map(removeWords, c("work", "from", "home"))%>%
    tm_map(removeWords,stopwords(kind="en"))%>%
    tm_map(stripWhitespace)

dtm<-DocumentTermMatrix(corpus.clean)

inspect(dtm[1:10,1:20])

df.train<-df[1:340,]
df.test<-df[341:680,]                                            

dtm.train<-dtm[1:340,]
dtm.test<-dtm[341:680,]

corpus.clean.train<-corpus.clean[1:340]
corpus.clean.test<-corpus.clean[341:680]

dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)

dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))

dim(dtm.train.nb)

dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))

dim(dtm.test.nb)
 
convert_count <- function(x){
    y<-ifelse(x>0,1,0)
    y<-factor(y,levels=c(0,1),labels=c("no","yes"))
    y
}

trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,2,convert_count)
#Training
classifier<-naiveBayes(trainNB, df.train$klasifikasi, laplace =1)

prediksi <- predict(classifier, testNB)

NB.table = table("Prediction"=prediksi, "Actual"=df.test$klasifikasi)
NB.table

conf.matNB <- confusionMatrix(prediksi, df.test$klasifikasi)
conf.matNB

```
```{r global}
dataLabel<- read.csv("datalabel.csv")
ui <- fluidPage(
    titlePanel("Sentiment Analysis Pajak"),
        mainPanel(
            
            tabsetPanel(type = "tabs",
                        tabPanel("Confusion Matrix and Statistic", verbatimTextOutput("result")),
                        tabPanel("Bagan", plotOutput("scatterplot")), 
                        # Plot
                        tabPanel("Data", DT::dataTableOutput('tbl1')),
                        # Output Data Dalam Tabel
                        tabPanel("Wordcloud", plotOutput("Wordcloud"))
                        )
        )
    )
# SERVER
server <- function(input, output) {
    
    # Output Data
    output$result <- renderPrint({
      conf.matNB
    })
    output$tbl1 = DT::renderDataTable({
        DT::datatable(dataLabel, options = list(lengthChange = FALSE))
    })

    output$scatterplot <- renderPlot({produk_dataset<-read.csv("dataPreprocessing.csv",stringsAsFactors = FALSE)

review <-as.character(produk_dataset$text)


s<-get_nrc_sentiment(review)

review_combine<-cbind(produk_dataset$text,s)
par(mar=rep(3,4))
barplot(colSums(s),col=c("yellow", "steelblue", "green", "orange"),ylab='count',main='Sentiment Analysis Pajak')
    }, height=400)
    output$Wordcloud <- renderPlot({
   set.seed(20)
df<-df[sample(nrow(df)),]
df<-df[sample(nrow(df)),]
glimpse(df)

inspect(dtm[1:10,1:20])

df.train<-df[1:50,]
df.test<-df[51:100,]

dtm.train<-dtm[1:50,]
dtm.test<-dtm[51:100,]

dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)

dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))

dim(dtm.train.nb)

dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))

dim(dtm.test.nb)
 
convert_count <- function(x){
    y<-ifelse(x>0,1,0)
    y<-factor(y,levels=c(0,1),labels=c("no","yes"))
    y
}
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)

wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))
  })
}
shinyApp(ui = ui, server = server)
```



